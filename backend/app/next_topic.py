from typing import List, Dict
from fastapi import HTTPException
from pydantic import BaseModel
from langgraph.graph import StateGraph, START, END
from langchain_openai import ChatOpenAI
import os, re
import logging

logger = logging.getLogger(__name__)

# -----------------------------------------------------------
# Step 1: State definitions

class OutlineBlock(BaseModel):
    title: str
    content: str

class TalkState(BaseModel):
    outline_sections: List[OutlineBlock]
    pointer: int = 0
    summary_so_far: str
    next_prompt: str | None = None

class NextTopicRequest(BaseModel):
    outline: str | None = None
    history: str
    pointer: int | None = 0

class NextTopicService:
    def __init__(self):
        self.llm = ChatOpenAI(model="gpt-4o-mini", temperature=0.3)
        self.graph = self._build_graph()
        logger.info("NextTopicService initialized")

    def _build_graph(self):
        g = StateGraph(state_schema=TalkState)
        g.add_node("choose", self.choose_next)
        g.add_node("prompt", self.craft_prompt)
        g.add_edge(START, "choose")
        g.add_edge("choose", "prompt")
        g.add_edge("prompt", END)
        return g.compile()

    def parse_structured_outline(self, outline: str | None) -> List[Dict[str, str]]:
        """
        Parse outline string like:
        1. ã€å­ä¸»é¢˜1ï¼šXXXã€‘\n - å¼€åœºå¼•å¯¼â€¦\n - è¦ç‚¹â€¦
        into a list of {title, content} blocks
        """
        if not outline:
            return [{"title": "è‡ªç”±æ¼”è®²", "content": "è¯·æ ¹æ®å†å²å†…å®¹ç»§ç»­æ¼”è®²"}]
            
        try:
            sections = re.split(r"\n\s*\d+\.\s+ã€(.*?)ã€‘", outline)
            result = []
            for i in range(1, len(sections), 2):
                title = sections[i]
                content = sections[i+1].strip()
                result.append({"title": title, "content": content})
            return result
        except Exception as e:
            logger.error(f"Error parsing outline: {str(e)}")
            return [{"title": "è‡ªç”±æ¼”è®²", "content": "è¯·æ ¹æ®å†å²å†…å®¹ç»§ç»­æ¼”è®²"}]

    def choose_next(self, state: TalkState) -> TalkState:
        if state.pointer >= len(state.outline_sections):
            raise HTTPException(status_code=200, detail="ğŸ‰ å·²ç»è®²å®Œå…¨éƒ¨å¤§çº²ï¼")
        return state

    def craft_prompt(self, state: TalkState) -> TalkState:
        block = state.outline_sections[state.pointer]

        system_msg = (
            "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ¼”è®²æç¤ºåŠ©æ‰‹ã€‚ä½ çš„ä»»åŠ¡æ˜¯å¸®åŠ©æ¼”è®²è€…ä¿æŒæ¼”è®²çš„è¿è´¯æ€§å’Œä¸“ä¸šæ€§ã€‚\n"
            "è¯·æ ¹æ®ä»¥ä¸‹è¦æ±‚ç”Ÿæˆæç¤ºï¼š\n"
            "1. æç¤ºåº”è¯¥ç®€æ´æ˜äº†ï¼Œæ¯ä¸ªè¦ç‚¹ä¸è¶…è¿‡20ä¸ªå­—\n"
            "2. æç¤ºåº”è¯¥è‡ªç„¶æµç•…ï¼Œç¬¦åˆæ¼”è®²çš„è¯­å¢ƒ\n"
            "3. æç¤ºåº”è¯¥å¸®åŠ©æ¼”è®²è€…è‡ªç„¶åœ°è¿‡æ¸¡åˆ°ä¸‹ä¸€ä¸ªè¯é¢˜\n"
            "4. å¦‚æœå¤§çº²ä¸­æœ‰å…·ä½“å†…å®¹ï¼Œè¯·ç¡®ä¿æç¤ºåŒ…å«è¿™äº›å…³é”®ç‚¹\n"
            "5. æç¤ºåº”è¯¥ä¿æŒä¸“ä¸šæ€§ï¼Œé¿å…å£è¯­åŒ–è¡¨è¾¾\n"
            "è¯·ç”Ÿæˆ3-5ä¸ªè¦ç‚¹ï¼Œæ¯ä¸ªè¦ç‚¹ç”¨çŸ­å¥è¡¨ç¤ºã€‚"
        )

        user_msg = f"""æ¼”è®²å†å²å†…å®¹ï¼š
{state.summary_so_far}

å½“å‰ç« èŠ‚æ ‡é¢˜ï¼š{block.title}
ç« èŠ‚å†…å®¹ï¼š{block.content}

è¯·æ ¹æ®ä»¥ä¸Šå†…å®¹ï¼Œç”Ÿæˆæ¥ä¸‹æ¥è¦è®²çš„è¦ç‚¹æç¤ºã€‚"""

        logger.info(f"Generating prompt for section: {block.title}")
        response = self.llm.invoke([
            {"role": "system", "content": system_msg},
            {"role": "user", "content": user_msg}
        ])

        state.next_prompt = response.content.strip()
        state.pointer += 1
        return state

    def get_next_topic(self, req: NextTopicRequest) -> Dict[str, str]:
        try:
            parsed = self.parse_structured_outline(req.outline)
            sections = [OutlineBlock(**p) for p in parsed]

            state = TalkState(
                outline_sections=sections,
                pointer=req.pointer or 0,
                summary_so_far=req.history
            )

            raw_result = self.graph.invoke(state)
            result = TalkState(**raw_result) 
            
            # å¦‚æœæ²¡æœ‰outlineï¼Œåªè¿”å›prompt
            if not req.outline:
                return {
                    "next_prompt": result.next_prompt
                }
                
            # æœ‰outlineæ—¶è¿”å›å®Œæ•´ä¿¡æ¯
            return {
                "next_prompt": result.next_prompt,
                "next_pointer": result.pointer,
                "remaining_sections": len(sections) - result.pointer,
                "current_title": sections[result.pointer - 1].title
            }
        except Exception as e:
            logger.error(f"Error getting next topic: {str(e)}")
            raise HTTPException(status_code=500, detail=str(e))

# æ£€æŸ¥å¿…è¦çš„ç¯å¢ƒå˜é‡
required_env_vars = ["OPENAI_API_KEY", "AZURE_SPEECH_KEY", "AZURE_SPEECH_REGION"]
missing_vars = [var for var in required_env_vars if not os.getenv(var)]
if missing_vars:
    raise ValueError(f"Missing required environment variables: {', '.join(missing_vars)}")
